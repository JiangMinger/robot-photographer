\section{\-Class \-List}
\-Here are the classes, structs, unions and interfaces with brief descriptions\-:\begin{DoxyCompactList}
\item\contentsline{section}{\hyperlink{class_g_photo2_handler}{\-G\-Photo2\-Handler} \\*\-Gphoto2 library wrapper for \-R\-O\-S framework }{\pageref{class_g_photo2_handler}}{}
\item\contentsline{section}{\hyperlink{struct_head}{\-Head} \\*\-Detected/tracked head structure }{\pageref{struct_head}}{}
\item\contentsline{section}{\hyperlink{class_r_p_autonomous_photography_node}{\-R\-P\-Autonomous\-Photography\-Node} \\*\-Robot photographer's picture-\/taking process coordinator node, which issues commands for taking and uploading the pictures }{\pageref{class_r_p_autonomous_photography_node}}{}
\item\contentsline{section}{\hyperlink{class_r_p_bayesian_skin_classifier}{\-R\-P\-Bayesian\-Skin\-Classifier} \\*\-Hue-\/histogram based \-Bayesian skin classifier }{\pageref{class_r_p_bayesian_skin_classifier}}{}
\item\contentsline{section}{\hyperlink{class_r_p_camera_node}{\-R\-P\-Camera\-Node} \\*\-Robot photographer's node which takes the pictures using the photographic camera via the gphoto2 library }{\pageref{class_r_p_camera_node}}{}
\item\contentsline{section}{\hyperlink{class_r_p_color_face_detector}{\-R\-P\-Color\-Face\-Detector} \\*\-Face detector in colour images, based on \-Viola and \-Jones (2001) face detector implementation in \-Open\-C\-V }{\pageref{class_r_p_color_face_detector}}{}
\item\contentsline{section}{\hyperlink{class_r_p_color_image_processor}{\-R\-P\-Color\-Image\-Processor} \\*\-Color image processor class, which provides implementations for simple color image manipulation tasks }{\pageref{class_r_p_color_image_processor}}{}
\item\contentsline{section}{\hyperlink{class_r_p_depth_head_detector}{\-R\-P\-Depth\-Head\-Detector} \\*\hyperlink{struct_head}{\-Head} detector from depth images }{\pageref{class_r_p_depth_head_detector}}{}
\item\contentsline{section}{\hyperlink{class_r_p_depth_head_tracker}{\-R\-P\-Depth\-Head\-Tracker} \\*\hyperlink{struct_head}{\-Head} tracker in depth images }{\pageref{class_r_p_depth_head_tracker}}{}
\item\contentsline{section}{\hyperlink{class_r_p_depth_image_processor}{\-R\-P\-Depth\-Image\-Processor} \\*\-Depth image processor class, which provides implementations for simple depth image manipulation tasks }{\pageref{class_r_p_depth_image_processor}}{}
\item\contentsline{section}{\hyperlink{struct_r_p_depth_head_detector_1_1_r_p_detected_head}{\-R\-P\-Depth\-Head\-Detector\-::\-R\-P\-Detected\-Head} }{\pageref{struct_r_p_depth_head_detector_1_1_r_p_detected_head}}{}
\item\contentsline{section}{\hyperlink{class_r_p_display_node}{\-R\-P\-Display\-Node} \\*\-Robot photographer's display node, which sends the status messages/hyperlinks via \-T\-C\-P to a corresponding client application that shows these messages }{\pageref{class_r_p_display_node}}{}
\item\contentsline{section}{\hyperlink{class_r_p_distance_converter}{\-R\-P\-Distance\-Converter} \\*\-Distance converter class, which converts between pixel and metric representations of given depth images }{\pageref{class_r_p_distance_converter}}{}
\item\contentsline{section}{\hyperlink{class_r_p_framing_node}{\-R\-P\-Framing\-Node} \\*\-Robot photographer's photographic composition node, which uses the human head locations provided by the head tracking node to calculate the most aesthetically pleasing framing for the picture }{\pageref{class_r_p_framing_node}}{}
\item\contentsline{section}{\hyperlink{class_r_p_heads_message_builder}{\-R\-P\-Heads\-Message\-Builder} \\*\-Detected/tracked head message builder class }{\pageref{class_r_p_heads_message_builder}}{}
\item\contentsline{section}{\hyperlink{class_r_p_head_tracking_node}{\-R\-P\-Head\-Tracking\-Node} \\*\-Robot photographer's head tracking node, which uses the colour and depth inputs from \-Kinect to detect and track humans in \-Luke's vicinity }{\pageref{class_r_p_head_tracking_node}}{}
\item\contentsline{section}{\hyperlink{class_r_p_kernel_logistic_regression_classifier}{\-R\-P\-Kernel\-Logistic\-Regression\-Classifier} \\*\-Kernel logistic regression classifier class }{\pageref{class_r_p_kernel_logistic_regression_classifier}}{}
\item\contentsline{section}{\hyperlink{class_r_p_k_l_r_classifier_gaussian_kernel}{\-R\-P\-K\-L\-R\-Classifier\-Gaussian\-Kernel} \\*\-Kernel logistic regression classifier \-Gaussian (radial basis function, \-R\-B\-F) kernel class }{\pageref{class_r_p_k_l_r_classifier_gaussian_kernel}}{}
\item\contentsline{section}{\hyperlink{class_r_p_k_l_r_classifier_kernel}{\-R\-P\-K\-L\-R\-Classifier\-Kernel} \\*\-Kernel logistic regression classifier kernel class }{\pageref{class_r_p_k_l_r_classifier_kernel}}{}
\item\contentsline{section}{\hyperlink{class_r_p_k_l_r_classifier_linear_kernel}{\-R\-P\-K\-L\-R\-Classifier\-Linear\-Kernel} \\*\-Kernel logistic regression classifier linear kernel class }{\pageref{class_r_p_k_l_r_classifier_linear_kernel}}{}
\item\contentsline{section}{\hyperlink{class_r_p_locomotion_node}{\-R\-P\-Locomotion\-Node} \\*\-Robot photographer's locomotion node, which converts driving direction messages and bumper press events into linear/angular velocity messages }{\pageref{class_r_p_locomotion_node}}{}
\item\contentsline{section}{\hyperlink{class_r_p_mock_head_tracking_node}{\-R\-P\-Mock\-Head\-Tracking\-Node} \\*\-Mock head tracking node that publishes randomly generated head detections, which evolve using a random walk over the scene. \-Useful for framing/composition algorithm testing }{\pageref{class_r_p_mock_head_tracking_node}}{}
\item\contentsline{section}{\hyperlink{class_r_p_navigation_node}{\-R\-P\-Navigation\-Node} \\*\-Robot photographer's navigation node, which multiplexes between the competing driving directions proposed by obstacle avoidance and photographic composition (framing) nodes }{\pageref{class_r_p_navigation_node}}{}
\item\contentsline{section}{\hyperlink{class_r_p_obstacle_avoidance_node}{\-R\-P\-Obstacle\-Avoidance\-Node} \\*\-Robot photographer's obstacle avoidance \-R\-O\-S node, which uses point cloud and depth image inputs to detect obstacles in front of the robot, and generates the driving directions accordingly }{\pageref{class_r_p_obstacle_avoidance_node}}{}
\item\contentsline{section}{\hyperlink{struct_r_p_framing_node_1_1_r_p_rectangle_comparator}{\-R\-P\-Framing\-Node\-::\-R\-P\-Rectangle\-Comparator} }{\pageref{struct_r_p_framing_node_1_1_r_p_rectangle_comparator}}{}
\item\contentsline{section}{\hyperlink{class_r_p_speech_node}{\-R\-P\-Speech\-Node} \\*\-Robot photographer's text-\/to-\/speech synthesis node, which vocalizes the input status messages using the \-Espeak library }{\pageref{class_r_p_speech_node}}{}
\item\contentsline{section}{\hyperlink{class_r_p_state_externalization_node}{\-R\-P\-State\-Externalization\-Node} \\*\-Robot photographer's node responsible for generating vocal/visual status messages about the internal state of the robot }{\pageref{class_r_p_state_externalization_node}}{}
\item\contentsline{section}{\hyperlink{struct_r_p_training_point}{\-R\-P\-Training\-Point} \\*\-Kernel logistic regression classifier training point }{\pageref{struct_r_p_training_point}}{}
\item\contentsline{section}{\hyperlink{class_r_p_utils}{\-R\-P\-Utils} \\*\-Utilities class for the head detection/tracking node }{\pageref{class_r_p_utils}}{}
\item\contentsline{section}{\hyperlink{class_usb_handler}{\-Usb\-Handler} \\*\-Helper class for basic \-U\-S\-B operations (like resetting the device) }{\pageref{class_usb_handler}}{}
\end{DoxyCompactList}
